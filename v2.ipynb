{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import custom\n",
    "import DocGPTMath\n",
    "import importlib\n",
    "importlib.reload(DocGPTMath)\n",
    "importlib.reload(custom)\n",
    "from custom import *\n",
    "from DocGPTMath import *\n",
    "import summarizer\n",
    "from langchain.agents import create_csv_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom.set_tokens(OPENAI_TOKEN='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',\n",
    "                  HF_TOKEN=\"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\")\n",
    "hf_embeddings = Embedding(model_name='sentence-transformers/all-MiniLM-L6-v2', model_type = 'hf')\n",
    "openai_embeddings = Embedding(model_type='openai')\n",
    "persona = Persona(personality_type='explainer')\n",
    "llm = Llm(model_type='gpt-3.5-turbo')\n",
    "llm_math_chain = LLMMathChain.from_llm(llm=llm.model, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vs_bnf_2000 = custom.load_vectorstore(store_name='store/BNF_OpenAI_embedded_2000.pkl')\n",
    "vs_rnd_2000 = custom.load_vectorstore(store_name='store/RnD_OpenAI_embedded_2000.pkl')\n",
    "vs_rnd_bnf_2000 = custom.load_vectorstore(store_name='store/RandD_BNF_OpenAI_embedded_2048.pkl')\n",
    "vs_bnf_5000 = custom.load_vectorstore(store_name='store/BNF_OpenAI_embedded_5000.pkl')\n",
    "#vs = VectorStore(embedding_model=openai_embeddings)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chain_bnf_2000 = Chain(retriever=Retriever(vs_bnf_2000, k=3), llm=llm, persona=persona)\n",
    "chain_bnf_5000 = Chain(retriever=Retriever(vs_bnf_5000, k=3), llm=llm, persona=persona)\n",
    "chain_rnd_2000 = Chain(retriever=Retriever(vs_rnd_2000, k=2), llm=llm, persona=persona)\n",
    "chain_rnd_bnf_2000 = Chain(retriever=Retriever(vs_rnd_bnf_2000, k=2), llm=llm, persona=persona)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chain = chain_rnd_2000\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"bnf_tool\",\n",
    "        func=chain_bnf_2000.qa.run,\n",
    "        description=\"useful for when you need to answer questions about specific drug doses, indications, contraindications, interactions, cautions.\",\n",
    "        return_direct=False\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"rnd_tool\",\n",
    "        func=chain_rnd_2000.qa.run,\n",
    "        description=\"useful for when you need to answer questions about drug mechanism of actions, pharmacokinetics and pharmacodynemics.\",\n",
    "        return_direct=False\n",
    "    ),\n",
    "    # Tool(\n",
    "    #     name=\"Calculator\",\n",
    "    #     func=llm_math_chain.run,\n",
    "    #     description=\"useful for when you need to answer questions about math\"\n",
    "    # )\n",
    "]\n",
    "agent = initialize_agent(tools, llm.model, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True, return_intermediate_steps=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = \"Summarize this book\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_obj = chain.qa(inputs={\"query\": query})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_obj['result']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "summary = summarizer.summarize(vectorstore=vs_rnd_2000, llm=llm, max_tokens=5000)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "summary"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "import pprint\n",
    "\n",
    "llm_txt = llm.model.model_name\n",
    "emb_txt = openai_embeddings.model.model\n",
    "status_code = \"### Model specifications <br> \\n\" + \"`LLM: \" + llm_txt + \"`\" + \" <br> `Embedding model: \" + emb_txt + \"`\"\n",
    "\n",
    "def chatbot(question, method):\n",
    "    print(method)\n",
    "    if method == 'Use Chain (Recommended)':\n",
    "        result_obj = chain.qa(inputs={\"query\": question})\n",
    "        result = result_obj['result']\n",
    "        steps_text = \"Running via single chain...\"\n",
    "    elif method == 'Use Agent (Experimental)':\n",
    "        result_obj = agent(inputs={\"input\": question})\n",
    "        result = result_obj['output']\n",
    "        steps_text = str(pprint.pformat(result_obj['intermediate_steps']))\n",
    "    #result = chain_rnd_bnf_2000.qa(inputs={\"query\": question})\n",
    "    #sources = ', \\n\\n'.join(str(doc) for doc in result['source_documents'])\n",
    "    return {output: output.update(value=result),\n",
    "            #acc: acc.update(value=sources)\n",
    "            steps: steps.update(value=steps_text)\n",
    "            }\n",
    "\n",
    "def get_sources_docs():\n",
    "    return os.listdir('data/')\n",
    "\n",
    "def get_vectors_list():\n",
    "    directory = 'store/'\n",
    "    pkl_files = [f for f in os.listdir(directory) if f.endswith('.pkl')]\n",
    "    return pkl_files\n",
    "\n",
    "def get_pkl_files():\n",
    "    return \", \\n\".join(get_vectors_list())\n",
    "\n",
    "def is_vectorstore_available():\n",
    "    return True if len(get_vectors_list()) > 0 else False\n",
    "\n",
    "def center_text(text):\n",
    "    return \"<div style='text-align:center;'>\" + text + \"</div>\"\n",
    "\n",
    "def build_vs(ins):\n",
    "    vs = VectorStore(embedding_model=openai_embeddings)\n",
    "    vs.save(store_name='store/vectorstore.pkl')\n",
    "    return {df: df.update(visible = True), btn : btn.update(visible=True), builder : builder.update(visible=False), rad:rad.update(value=\"Ready\")}\n",
    "\n",
    "with gr.Blocks(theme=gr.blocks.themes.Default()) as demo:\n",
    "    source_list = \", \\n\\n\".join(get_sources_docs())\n",
    "    pkl_files = \", \\n\\n\".join(get_vectors_list())\n",
    "\n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "        <h1 align=\"center\">\n",
    "        docGPT!\n",
    "        </h1>\n",
    "        <p align=\"center\">\n",
    "        version 1.2.\n",
    "        </p>\n",
    "\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    with gr.Row(equal_height=True):\n",
    "        gr.Textbox(interactive=False, value=source_list, min_width=1, label=\"Documents in current knowledgebase\")\n",
    "        with gr.Column():\n",
    "            v_txt = gr.Textbox(interactive=False, value=get_pkl_files(), min_width=1, label=\"Available vectorstores\", visible=False)\n",
    "            rad = gr.Radio(choices=['Ready', 'Not built'], value= \"Ready\" if is_vectorstore_available() else 'Not built', interactive=False, label=\"Vector store status\")\n",
    "            stats = gr.Markdown(status_code)\n",
    "            agent_toggle = gr.Radio(choices=['Use Chain (Recommended)', 'Use Agent (Experimental)'], value='Use Chain (Recommended)', label='Run method', interactive=True)\n",
    "    builder = gr.Button(\"Build vector store\", visible = not is_vectorstore_available())\n",
    "\n",
    "\n",
    "    with gr.Row(visible=True if is_vectorstore_available() else False) as df:\n",
    "        input = gr.Textbox(label='Ask your question specifically.')\n",
    "        output = gr.Textbox(label='Answer')\n",
    "    #acc = gr.Textbox(label=\"Sources\", max_lines=10)\n",
    "    steps = gr.Textbox(label=\"Method info\", max_lines=5)\n",
    "\n",
    "    btn = gr.Button(\"Ask docGPT\", visible=True if is_vectorstore_available() else False)\n",
    "    #btn.click(fn = chatbot, inputs=input, outputs=[output, acc],api_name='answer')\n",
    "    btn.click(fn = chatbot, inputs=[input, agent_toggle], outputs=[output, steps],api_name='answer')\n",
    "\n",
    "    builder.click(fn=build_vs, outputs=[df, btn, rad, builder])\n",
    "\n",
    "demo.launch(debug=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
